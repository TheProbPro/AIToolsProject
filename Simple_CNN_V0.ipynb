{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5701243c",
   "metadata": {},
   "source": [
    "# # CIFAR-10 CNN Classifier - Comprehensive Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b5bac",
   "metadata": {},
   "source": [
    "# ## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc66d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3140cd6",
   "metadata": {},
   "source": [
    "# ## 2. Helper Functions for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4684fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_auc(y_true, y_score, num_classes, classes):\n",
    "    y_true_bin = label_binarize(y_true, classes=np.arange(num_classes))\n",
    "    fpr, tpr, roc_auc = {}, {}, {}\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n",
    "        roc_auc[i] = roc_auc_score(y_true_bin[:, i], y_score[:, i])\n",
    "        plt.plot(fpr[i], tpr[i], label=f'{classes[i]} (AUC={roc_auc[i]:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for Each Class')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "def plot_metric_bar(metrics_df, metric_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=metrics_df.index, y=metric_name, data=metrics_df)\n",
    "    plt.title(f'{metric_name} per Class')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    for i, v in enumerate(metrics_df[metric_name]):\n",
    "        plt.text(i, v + 0.02, f\"{v:.2f}\", ha='center')\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_history(train_losses, train_accuracies):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    ax1.plot(train_losses, label='Training Loss')\n",
    "    ax1.set_title('Training Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.plot(train_accuracies, label='Training Accuracy')\n",
    "    ax2.set_title('Training Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3dd9c",
   "metadata": {},
   "source": [
    "# ## 3. CNN Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7041bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971dd6bf",
   "metadata": {},
   "source": [
    "# ## 4. Data Loading and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "classes = train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed181a7a",
   "metadata": {},
   "source": [
    "# ## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42754d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(num_classes=10).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = total_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "    # Plot training history\n",
    "plot_training_history(train_losses, train_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad5c7d",
   "metadata": {},
   "source": [
    "# ## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bcc63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_labels, all_preds, all_probs = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        _, predicted = outputs.max(1)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(all_labels, all_preds, target_names=classes, digits=4, output_dict=True)\n",
    "metrics_df = pd.DataFrame(report).transpose().iloc[:-3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c179ab3",
   "metadata": {},
   "source": [
    "# ## 7. Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ee663",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(all_labels, all_preds, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e11a761",
   "metadata": {},
   "source": [
    "# ## 8. Accuracy Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5045f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(['Overall Accuracy'], [report['accuracy']])\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Overall Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "for i, v in enumerate([report['accuracy']]):\n",
    "    plt.text(i, v + 0.02, f\"{v:.4f}\", ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3367a494",
   "metadata": {},
   "source": [
    "# ## 9. Precision Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c72cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_bar(metrics_df, 'precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2e086e",
   "metadata": {},
   "source": [
    "# ## 10. Recall (Sensitivity) Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_bar(metrics_df, 'recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec4e9fb",
   "metadata": {},
   "source": [
    "# ## 11. F1-Score Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric_bar(metrics_df, 'f1-score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61316110",
   "metadata": {},
   "source": [
    "# ## 12. Support Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c1d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=metrics_df.index, y='support', data=metrics_df)\n",
    "plt.title('Number of Samples per Class (Support)')\n",
    "plt.xticks(rotation=45)\n",
    "for i, v in enumerate(metrics_df['support']):\n",
    "    plt.text(i, v + 20, str(v), ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c09e94",
   "metadata": {},
   "source": [
    "# ## 13. ROC Curve & AUC Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_auc(all_labels, np.array(all_probs), num_classes=10, classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23324f7e",
   "metadata": {},
   "source": [
    "# ## 14. Detailed Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(all_labels, all_preds, target_names=classes, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
